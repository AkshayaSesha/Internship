# -*- coding: utf-8 -*-
"""Movie Reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-c9ftLmMbkbc985-ElzHhS5pQax9L7kZ
"""

import numpy as np
import pandas as pd

data= pd.read_csv('/content/IMDB Dataset.csv')

data.head()

data.info()

data.describe()

data['review'] = data['review'].str.lower()

data['review']

text = data['review'][1]
text

import re
def remove_html_tags(text):
    pattern=r'[^a-zA-z0-9\s]'
    text = re.sub(pattern,'',text)
    return text
data['review'] = data['review'].apply(remove_html_tags)

data['review']

import nltk

# Download the stopwords corpus
nltk.download('stopwords')

from nltk.corpus import stopwords

# Now load the stopwords
stop_words = stopwords.words('english')
print(stop_words)

def stopwords_removal(text):
    new_text = []
    words_list = text.split()
    stopwords_list = stopwords.words('english')

    for word in words_list:
        if word not in stopwords_list:
            new_text.append(word)

    return ' '.join(new_text)

data['review'] = data['review'].apply(stopwords_removal)
data['review'][1]

data.head()

import string

punctuations = string.punctuation

def punctuation_removal(text):
    text = text.translate(str.maketrans('', '', punctuations))
    return text

data['review'] = data['review'].apply(punctuation_removal)
data['review'][1]

from nltk import PorterStemmer
ps = PorterStemmer()

data['review'] = data['review'].apply(lambda x: ps.stem(x))
data['review'][2]

data.head()

import matplotlib.pyplot as plt
import seaborn as sns

data['sentiment'].value_counts()

sentiment_counts = data['sentiment'].value_counts()
plt.figure(figsize=(8, 6))
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['red', 'green'])

plt.title('Distribution of Positive and Negative Movie Reviews', fontsize=16)
plt.xlabel('Sentiment', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(ticks=[0, 1], labels=['Negative', 'Positive'], fontsize=12)

plt.show()

sentiment_counts = data['sentiment'].value_counts()
labels = ['Negative', 'Positive']
colors = ['red', 'green']

plt.figure(figsize=(7, 7))
plt.pie(sentiment_counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors, explode=[0.1, 0], shadow=True)

plt.title('Distribution of Positive and Negative Movie Reviews', fontsize=16)
plt.axis('equal')

plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
df = pd.read_csv('IMDB Dataset.csv')
tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)
X = tfidf.fit_transform(df['review'])
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'KNN Accuracy: {accuracy * 100:.2f}%')

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Random Forest Accuracy: {accuracy * 100:.2f}%')

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

y_pred = dt.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Decision Tree Accuracy: {accuracy * 100:.2f}%')

from sklearn.svm import SVC
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)

y_pred = svm.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'SVM Accuracy: {accuracy * 100:.2f}%')